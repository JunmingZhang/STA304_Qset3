---
title: "Use a frequentis multilevel logistic regression model (random intercept) to predict 2020 American Federal Election result and post-stratification to verify the model"
subtitle: "Apply the frequentis multilevel logistic regression model and make diagnosis on the performance of the model"
author: "Junming Zhang, Hairong Sun, Xiaoxi Bai, Yangyang Liu"
date: "`r Sys.setenv(TZ='EST'); format(Sys.time(), '%A, %B %d, %Y')`"
abstract: |
  | This report focused on using a frequentis multilevel regression model (random intercept) to predict if Donald Trump or Joe Biden can be selected as 2020 USA president. In order to build the model, we use a survey dataset (Tausanovitch, Chris and Lynn Vavreck, 2019)(Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas and Matthew Sobek, 2020) to build the model and a census dataset (PUMS USA, 2020) to predict who will be elected for post stratification purpose. Our model predicts that Joe Biden will be elected with significant superiority with respect to electoral votes, and we discussed the result. However, since there are some drawbacks in our model, we also discuss the weakness and how we can improve it.
  |
  | **key words:** USA 2020 election, Donald Trump, Joe Biden, multilevel logistic regression model, post-stratification, prediction
header-includes:
   - \usepackage{xcolor}
output:
  pdf_document: default
  html_document:
    df_print: paged
---

\textcolor{red}{\underline{Please click \href{https://github.com/JunmingZhang/STA304_Qset3.git}{\textbf{"here"}} to access the GitHub repository for all work.}}

```{r setup, include=FALSE}
# use tidyverse and brms to build the model and manipulate the data
library(tidyverse)
library(magrittr)
# library(brms)
library(lme4)
library(PRROC)
library(caret)

# Loading in the cleaned survey Data
# from (Tausanovitch, Chris and Lynn Vavreck, 2020)
survey_data <- read_csv("outputs/survey_data.csv")

# Loading in the cleaned census Data
# from (Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas and Matthew Sobek, 2020) and
# and (PUMS USA)
census_data <- read_csv("outputs/census_data.csv")
```

# Model
In this model, we are predicting the vote outcome of the 2020 American federal election by employing random intercept model and post-stratification technique. In the following sub-sections we will describe the logistic model regression specifics and the post-stratification calculation.


## Model Specifics
We will be using a random intercept model to model the voters who will vote for Donald Trump run by R studio. We will be using sex, age_group, race, hispan, education, state, and vote_trump to model the probability of voting for Donald Trump. The logistic regression model we are using is:

$$\log\frac{p}{1-p} = \beta_0 + \beta_1 * sexmale +\beta_2 * age\_group18-20 + ... + \beta_{18} * educationtertiary\ \ (not\ \ bachelor) + \epsilon $$ 

Where p is the probability of Donald Trump got selected. $\log\frac{p}{1-p}$ is the odds of trump winning the election. $\beta_0$ represents intercept of the model which is $2.10152$. Residual epsilon represents the error. Additionally, $\beta_1 to \beta_{18}$ represent the slope of the model, and relate to each variables. $\beta_1 = 0.41511$, $\beta_2 = -1.62472$, ..., $\beta_{18} = -0.45434$ respectively according to the summary data. So, for example, for everyone one unit increase in sexmale, we expect a $\beta_1$ increase in the probability of voting for Donald Trump.


```{r, include=FALSE}

# select cols we need
survey_set <-
  survey_data %>% select(sex, age_group, race, hispan, education, state, vote_trump)
census_set <-
  census_data %>% select(sex, age_group, race, hispan, education, state, perwt)

# Creating the Model
# model <- lm(vote_trump ~ age, 
#             data=survey_data)


# Model Results (to Report in Results section)
# summary(model)
# OR
# broom::tidy(model)

```


```{r, echo=FALSE, message=FALSE}
# look at the statistics of the dataset
summary(survey_set)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# we change the some cols to factors for building the model with tidyverse
# also look at the dataset
survey_set %<>%
       mutate_each_(funs(factor(.)), c("sex", "age_group", "race", "hispan", "education", "state"))
summary(survey_set)
```


```{r, echo=FALSE}
# look at the percentage of voters who vote Donald Trump
# this is just a brief check (not formal) without considering Electoral College
survey_set %>% summarise(prop_vote_trump = sum(vote_trump) / nrow(survey_set))
```


```{r, include=FALSE, warning=FALSE}
# do not use brms because of limits on library
# model <- brm(vote_trump ~ sex + age_group + race + hispan + education + (1|state),
#              data = survey_set,
#              family = bernoulli())

# create the logistic regression model with logistic regression (a Random Intercept Model),
# in this model, I use the state as cell
# use vote_trump so the model predicts the odds (or prob) Trump get selected
model <- glmer(vote_trump ~ sex + age_group + race + hispan + education + (1|state),
                     data = survey_set, 
                     family=binomial)
```


```{r, include=FALSE}
# make predictions
preds = predict(model, new_data=survey_set, type=c("response"))
pred_result = ifelse(preds > 0.5, 1, 0)
survey_result = tibble(prediction=pred_result, label=survey_set$vote_trump)
```


```{r, echo=FALSE}
# use a table to show the information about the model (p_value, etc.)
# used for diagonalise, including p-value
summary(model)
```

## Logistic: ROC and PR curve

ROC (Receiver Operating Characteristics) curve plot is a visualization of the sensitivity and FPR. The larger the area under the curve (AUC, max = 1) is, the better the curve is. In this model, the AUC is 0.6451397, which means that the performance of this model is moderately credible. PRC (Precision-recall Curve) is used for showing the relation between precision and recall. The AUC is 0.6063118. Therefore, this model can have predictive value if the value is properly set, which is more accurate than random guessing.


```{r, echo=FALSE}
# plot a roc and prc (precision-recall curve) to make diagonalise on the model
roc_obj <- roc.curve(scores.class0 = survey_result$prediction, weights.class0=survey_result$label, curve=TRUE)
plot(roc_obj)

pr_obj = pr.curve(scores.class0 = survey_result$prediction, weights.class0=survey_result$label, curve=TRUE)
plot(pr_obj)
```



## Logistic: Confusion Matrix and Accuracy

The confusion matrix is used for summarizing predicted result and check the true positive and true negative rate of the model. It also gives an accuray about 0.6484, which is not bad in terms of true positive and true negative rate. Also seen from the confusion matrix below, the false positive rate is more than half of the true positive rate (ratio: $\frac{890}{1438}$), and the false negative rate is nearly half of the true negative rate (ratio: $\frac{329}{810}$). Therefore, the model performs terribly with respect to false positive rate and not well with respect to false negative rate.


```{r, echo=FALSE}
# show accuracy and confusion matrix of the model
confusionMatrix(as.factor(survey_result$prediction), as.factor(survey_result$label))
```


## Post-Stratification 

Post-stratification refers to the random sampling of a population and sampling of a sample n. After the survey, n units are divided into several layers according to certain stratification factors. Then stratified sampling estimation is carried out. In this project, post stratification is collecting the census data and applying the MR model to the census data to predict each individuals’ voting result. It is useful because it is difficult to stratify the whole in a certain way beforehand. And the operation is simple, low cost, in the case of incomplete information, can be applied. In order to estimate the proportion of voters who will vote for Donald Trump we need to perform a post-stratification analysis. Here we create cells based on different states. Using the model described in the previous sub-section we will estimate the proportion of voters in each state. We will then weight each proportion estimate (within each state) by the respective population size of that state and sum those values and divide that by the entire population size. The reason why we choose "state" is because each state have electoral votes (total 538 votes this year) and who won more than 270 electoral votes wins the election [16]. Therefore, it is essential to predict according to states.

```{r, echo=FALSE, warning=FALSE}
# we change the some cols to factors for using the model to make predictions on the census data
# also look at the dataset
census_set %<>%
       mutate_each_(funs(factor(.)), c("sex", "age_group", "race", "hispan", "education", "state"))
summary(census_set)
```


```{r, include=FALSE}
# calculate the weight for each person in his own cell (which is state in our model)
census_set %>%
  group_by(state) %>%
  mutate(cell_prop_of_division_total = perwt / sum(perwt)) -> census_set

# Here I will perform the post-stratification calculation
census_set$estimate <-
  model %>%
  predict(newdata = census_set, type=c("response"))

# census_data$estimate <-
#   model %>%
#   predict(newdata = census_data)

# census_data %>%
#   mutate(alp_predict_prop = estimate*n) %>%
#   summarise(alp_predict = sum(alp_predict_prop)/sum(n))


```


```{r, echo=FALSE}
census_set %>%
  mutate(trump_predict_prop = estimate * cell_prop_of_division_total) %>%
  group_by(state) %>%
  summarise(trump_predict = sum(trump_predict_prop), .groups = 'drop') -> ps_result
ps_result
```

# Results

In this section, we will predict whether Donald Trump or Joe Biden will win the final federal election. The total number of electoral votes is 538, and the proportion of people who are willing to vote for Trump is predicted to be around 51% by using survey data. However this result has no personal weight which means that it cannot be used as the final result. It can only be used as a reference for future predictions. Therefore, we make predictions about the outcome of the general election by considering the electoral college. This model is accounted for variables of “sex” “age_group”, “race”, “hispan”, "state" and "education". There are 51 states in America based on the dataset. We will predict the voting situation of these state voters. The prediction results show that there are 27 states where the percentage of voting Trump is between 0.4 and 0.5. For example, the state of  Alaska (AK) has a 0.468 (46.8%) predicted voting rate of Trump. In the state of Alabama (AL), the number is 0.500 (50.0%). It is very balanced. Trump and Biden would do more campaigns on this kind of states to increase the possibility of winning. Moreover, the result demonstrates that in the state of California (CA) and Connecticut (CT), Trump’s support is slightly weaker, with only 0.402 (40.2%) and 0.381 (38.1%) under the estimation. However, in the state of Arkansas (AR) and Montana (MT) the support rate for Trump is relatively high with rate of 0.560 (56.0%) and 0.583 (58.3%). In the state of District of Minnesota (MN) and Maryland (MD), we predict that voters’ support for Trump would be the lowest, 0.353 (35.3%) and 0.345 (34.5%) respectively. According to our model's prediction result, Joe Biden will receive a total of 422 electoral votes, while Donald Trump will only receive 116 electoral votes. Joe Biden has more states in favor of voting for him, so we expect democratic presidential candidate, Joe Biden, to win the election.

```{r, echo=FALSE}
# here we predict who will win the federal election
# make predictions by considering Electoral College
ps_result$elected <- ifelse(ps_result$trump_predict > 0.5, "Donald Trump", "Joe Biden")

# number of electoral votes (citation 10)
# total electoral votes: 538
ps_result <- ps_result %>%
  mutate(electoral_vote_dist=
           case_when(
             state=="AL" ~ 9, state=="AK" ~ 3, state=="AZ" ~ 11, state== "AR" ~ 6,
             state=="CA" ~ 55, state=="CO" ~ 9, state=="CT" ~ 7, state=="DE" ~ 3,
             state=="DC" ~ 3, state=="FL" ~ 29, state=="GA" ~ 16, state=="HI" ~ 4,
             state=="ID" ~ 4, state=="IL" ~ 20, state=="IN" ~ 11, state=="IA" ~ 6,
             state=="KS" ~ 6, state=="KY" ~ 8, state=="LA" ~ 8, state=="ME" ~ 4,
             state=="MD" ~ 10, state=="MA" ~ 11, state=="MI" ~ 16, state=="MN" ~ 10,
             state=="MS" ~ 6, state=="MO" ~ 10, state=="MT" ~ 3, state=="NE" ~ 5,
             state=="NV" ~ 6, state=="NH" ~ 4, state=="NJ" ~ 14, state=="NM" ~ 5,
             state=="NY" ~ 29, state=="NC" ~ 15, state=="ND" ~ 3, state=="OH" ~ 18,
             state=="OK" ~ 7, state=="OR" ~ 7, state=="PA" ~ 20, state=="RI" ~ 4,
             state=="SC" ~ 9, state=="SD" ~ 3, state=="TN" ~ 11, state=="TX" ~ 38,
             state=="UT" ~ 6, state=="VT" ~ 3, state=="VA" ~ 13, state=="WA" ~ 12,
             state=="WV" ~ 5, state=="WI" ~ 10, state=="WY" ~ 3
           ))

ps_result %>% group_by(elected) %>%
  summarise(total_electoral_votes = sum(electoral_vote_dist), .groups = 'drop')
```

# Discussion

## Summary
We try to build a logistic regression model to predict whether Donald Trump or Joe Biden will win the final federal election. First, we use the electoral college to predict the outcome of the general election and select the variables “sex, age_group”, “race”, “hispan”, “education”, and “state” to create our model. Then we made the final model diagnosis by judging AIC and BIC, observing p-value, roc curve, pc curve, and confusion matrix.

Then we conducted Post-Stratification, which is a random sampling of a population. In the case of insufficient information, we can use the MR model to predict census data to predict the voting result and perform a post-Stratification analysis. We will predict the proportion of voters in favour of voting in each state and calculate who won more than 270 votes at the end. Therefore, we will predict the voting situation of voters in 51 states in the U.S. Among them, from the model prediction results, we can see that voters in Arkansas (AR) and Montana (MT) tend to vote for Trump. However, in Minnesota (MN) and Maryland (MD) states, Trump is predicted to have low approval rate, indicating that Joe Biden has a relatively high win rate in these states. By calculating total electoral votes, we estimate that Joe Biden will receive a total of 422 electoral votes, while Donald Trump will only receive 116 electoral votes; therefore, we expect the democratic presidential candidate Biden to win the final election.


## Conclusion

In conclusion, we predict that Joe Biden who is the presidential nominee of democratic party would win in the election. Based on our model, Joe Biden would get 422 electoral votes in total while Donald Trump would only get 116 electoral votes. The difference is quite big because Joe Biden has much more states that in favour of voting him based on our model.


## Weaknesses
Based on the above analysis, there are a few weaknesses of this model. First, the number of variables is quite small in both dataset and model. In the model, we only use 6 variables and we mainly focus on the demographic variables. We neglect variables that keep abreast of times. For example, in the 2016 US election, the Facebook marketing plays a key factor in Trump’s winning [11]. However, the datasets of census and survey do not provide this kind of campaign variables. Thus, the model would be out of date for election of this year. Second, the dataset of census does not contain the information on people’s party preference on democratic and republican. People who like democratic better would be more likely to vote for Joe Biden while people who like republican more would vote for Donald Trump. With this information, the model would be more precise. We could have a basic estimate on the voting of Joe Biden and Donald Trump. However, this information is not available. Third, when we build the model, we do not consider income factor. Typically, voters for Donald Trump are people who have a lower income while people who has a higher income tend to vote for Joe Biden. Although the income variable in census represents personal total income and the one in survey represents household income, we should still take income into this model. Fourth, when we clean the raw data of census, we are too general on some specific variables. For example, when we clean the variable of race, we combine Asian and Pacific Islander together for convenience. There are a lot of groups under Asian like Chinese, Korean, Japanese and so on. These groups would have some trends on voting based on their background and this may influence the result of election a lot. Nonetheless, we ignore these features in the model and this would cause a weak prediction. Furthermore, it is worth noting that education variable plays a very important role in the election. When we design the survey of election preference, we should include more people that have lower education level. In the survey dataset, it includes more people who have higher education level, and this would make the prediction in favor of Joe Biden [12].  People with higher education level would be more likely to vote for Joe Biden [12]. 

## Next Steps
In order to make the estimation of model more accurate, we should find ways to eliminate the above weaknesses. For instance, we could clean the data in a more detailed way and include more variables in the analysis. We should also include survey that contains more people that has lower education level.  Since the election result would be out on November 3rd, we could compare the actual result of election with our prediction. We need to do a post-hoc analysis. First, we could figure out if our prediction result match the real result. And then, we should know how big the difference is between the predicted total electoral votes and the actual one. If the difference is very big, we may need to switch to another model. For example, we could use Principal Component Analysis (PCA) which is an algorism that decreases dimensional space to start the model [13]. This would eliminate some unnecessary variables from the data and mainly focus on the key principles to predict the election. It is also important to figure out which factor is the key success factor on the election. If we do not include that in the model, we definitely need to add that. After, the analysis, we could redesign the model and check if the new one provides a result that is closer to the actual result. Moreover, some machine learning technology could help us to build a better model. The use of artificial neural networks, which is a brain-spired system, would help the model a lot [14]. It would decrease the uncertainty of the model. All of these would better improve the estimation of this model in future elections. 


# References
```{r, include=FALSE}
citation("tidyverse")
citation("magrittr")
citation("lme4")
citation("PRROC")
citation("caret")
```
<!-- dataset -->
1. Tausanovitch, Chris and Lynn Vavreck. 2020. Democracy Fund + UCLA Nationscape, October 10-17, 2019 (version 20200131). Retrieved from [URL].
2. Steven Ruggles, Sarah Flood, Ronald Goeken, Josiah Grover, Erin Meyer, Jose Pacas and Matthew Sobek. IPUMS USA: Version 10.0 [dataset]. Minneapolis, MN: IPUMS, 2020. https://doi.org/10.18128/D010.V10.0
3. PUMS USA, University of Minnesota, www.ipums.org.
<!-- code -->
4. Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686
5. Stefan Milton Bache and Hadley Wickham (2014). magrittr: A Forward-Pipe Operator for R. R package version
  1.5. https://CRAN.R-project.org/package=magrittr
6. Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using
  lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.
7. Jens Keilwagen, Ivo Grosse and Jan Grau (2014). Area under Precision-Recall Curves for Weighted and
  Unweighted Data. PLOS ONE (9) 3.
8. Jan Grau, Ivo Grosse, and Jens Keilwagen (2015). PRROC: computing and visualizing precision-recall and
  receiver operating characteristic curves in R. Bioinformatics (31) 15, pp. 2595-2597.R package version
  1.3.1.
9. Max Kuhn (2020). caret: Classification and Regression Training. R package version 6.0-86.
  https://CRAN.R-project.org/package=caret
<!-- other -->
10. United States Electoral College Votes by State. (n.d.). Retrieved November 01, 2020, from https://www.britannica.com/topic/United-States-Electoral-College-Votes-by-State-1787124
11. Bump, P. (2019, March 29). All the ways Trump's campaign was aided by Facebook, ranked by importance. Retrieved November 02, 2020, from https://www.washingtonpost.com/news/politics/wp/2018/03/22/all-the-ways-trumps-campaign-was-aided-by-facebook-ranked-by-importance/
12. How Race and Educational Attainment Factor Into Biden's 2020 Lead. (2020, September 17). Retrieved November 02, 2020, from https://morningconsult.com/2020/09/17/trump-biden-race-education-voters/
13. Jaadi, Z. (n.d.). A Step by Step Explanation of Principal Component Analysis. Retrieved November 02, 2020, from https://builtin.com/data-science/step-step-explanation-principal-component-analysis
14. Dormehl, L. (2019, January 06). What is an artificial neural network? Here's everything you need to know. Retrieved November 02, 2020, from https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/
15. Who Can and Can't Vote in U.S. Elections. (n.d.). Retrieved November 02, 2020, from https://www.usa.gov/who-can-vote 
16. Presidential Election Process. (n.d.). Retrieved November 02, 2020, from https://www.usa.gov/election